import json
import random

from autotest_lib.server import autotest, hosts, subcommand
from autotest_lib.server import utils

TEST_URL = 'http://ceph.newdream.net:8116/tarball/master/ceph_pjd_fstest.tar.bz2'

ROLES = [
    [
        'mon.0',
        'mds.0',
        ],
    [
        'mon.1',
        'mds.1',
        ],
    [
        'mon.2',
        'mds.2',
        ],
    [
        'osd.0',
        ],
    [
        'osd.1',
        ],
    [
        'client.0',
        ],
    ]

CLIENT_TYPES = {
    'client.0': 'kclient',
    }

def run((tag_name, cluster)):
    assert len(cluster) == len(ROLES)
    all_hosts = [hosts.create_host(host_name) for host_name in cluster]
    all_at = [autotest.Autotest(host) for host in all_hosts]
    cookie = '%032x'%random.getrandbits(128)
    template = "import json; data=json.loads({data!r}); job.cache=False; job.run_test(**data)"

    def g():
        for i in range(len(ROLES)):
            control_file = template.format(data=json.dumps(dict(
                        url=TEST_URL,
			cookie=cookie,
                        number=i,
                        all_roles=ROLES,
                        all_ips=[host.ip for host in all_hosts],
                        client_types=CLIENT_TYPES,
                        tag=tag_name,
                    )))

            command = subcommand.subcommand(
                all_at[i].run,
                [control_file, all_hosts[i].hostname],
                )
            yield command

    subcommand.parallel(list(g()))

# grab the pairs (and failures)
(clusters, failures) = utils.form_ntuples_from_machines(machines, len(ROLES))

# log the failures
for failure in failures:
    job.record("FAIL", failure[0], "ceph_pjd_fstest", failure[1])

named_clusters = [('cluster%d'%i,  machines) for (i, machines) in enumerate(clusters)]

# now run through each pair and run
job.cache = False
job.parallel_simple(run, named_clusters, log=False)
